# Vertex Buffer
Create a vertex buffer to push the vertices instead of hardcoding them.

## Vertex Input description
We will start by updating the vertex shader to include per-vertex inputPosition and inputColor properties.

We create a new Vertex class to hold the vertex data and populate it.

Then we need to inform the Vulkan how to upload the data in the GPU, we do this with an inputBinding Description.
We need to specify the binding "location", sizeof the data and the inputRate which can of 2 types
    - Vertex: Move to the next data entry after each vertex
    - Instace: Move to the next data entry after each instace.

Then we need to create the Input Attribute Description to describe how to handle vertex input.
We are going to create 2 attribute descriptions because we send 2 item, the position and the colour.
We need to specify the binding, location, format and offset.
The format is what type should we map in shader.
The offset is the number of bytes we need to offset to get to the attribute we need.

Lastly, we need to supply this to the pipeline so that Vulkan can send the appropriate information to the shader.

## Vertex Buffer creation
Buffers in Vulkan are regions of memory used for storing arbitrary data that can be read by the graphics card.
They can be used to store vertex data along other things. Unlike other vulkan objects, we need to allocate memory for the buffers ourselves.

### Buffer Creation
To create a buffer we need to fill up some fields.
    - The size of the buffer,
    - The usage type, in this case vertex
    - The sharing mode, which states if the buffer is owned by a specific queue family or shared between multiple.

### Memory Requirements && Allocation
After the buffer is created, we need to allocate memory to it. But to allocate the memory we need to find out the requirements.
To do that we need to call the `get_buffer_requirements` using the buffer as the parameter.
Using the requirements now we will try to find a memory from the memory types that fits both the requirements of the buffer, as well as the required properties that we need,
in this case the memory type needs to be `CPU_VISIBLE`

We may have more than one desirable property, so we should check if the result of the bitwise AND is not just non-zero, but equal to the desired properties bit field. If there is a memory type suitable for the buffer that also has all of the properties we need, then we return its index, otherwise we throw an exception.

To allocate the memory we just picked we need to use the following function `allocate_memory` with the parameters:
    - memory_type_id: The memory type we just picked
    - size: The size in bits we need to allocate, Use the memory requirements size property to set that

Lastly, we need to bind the memory we just allocated and bind it to the buffer.
Similar to the allocation abouve, we will use the `bind_buffer_memory` with the following parameters
    - memory: The allocated memory
    - offset: The offset of the memory
    - buffer: A pointer to the buffer we created

Lastly, let's not forgot to remove and deallocate the memory on the cleanup operation.

### Filling the vertex buffer
Once we have created the vertex buffer, we want to fill it up with the vertices of the quad.

To do so firstly, we need to map the memory using the `map_memory` method with the parameters 
    - memory: the allocated memory
    - size: from 0 to memory.size
This function returns to use the memory address.

Then we need to copy the vertex data to that the memory using the `ptr::copy_nonoverlapping`

Notes:  the driver may not immediately copy the data into the buffer memory, for example because of caching. It is also possible that writes to the buffer are not visible in the mapped memory yet. There are two ways to deal with that problem:
    - Use a memory heap that is host coherent, using the `Coherent` flag
    - Call `flush_mapped_memory_ranges` after writing the mapped memory and call the `invalidate_mapped_memory_ranges` before reading from the mapped memory

We went for the first approach, which ensures that the mapped memory always matches the contents of the allocated memory. Do keep in mind that this may lead to slightly worse performance than explicit flushing, but we'll see why that doesn't matter in the next chapter.

Flushing memory ranges or using a coherent memory heap means that the driver will be aware of our writes to the buffer, but it doesn't mean that they are actually visible on the GPU yet. The transfer of data to the GPU is an operation that happens in the background and the specification simply [tells us](https://www.khronos.org/registry/vulkan/specs/1.0/html/vkspec.html#synchronization-submission-host-writes) that it is guaranteed to be complete as of the next call to `vkQueueSubmit`.

### Binding the vertex buffer
The last thing we need to do, is bind the vertex buffer to the pipeline so that it can be used in shaders.
This needs to be done during the rendering process, using the `bind_vertex_buffers` with the parameters:
    - first_binding: this is the offset on the locations where the buffers should be bind
    - buffers: a list of the buffers with the binding offset.

## Staging Buffer
Using a vertex buffer works, but having it accessible by a CPU isn't optimal. We need to something that is not accessible by the CPU from the GPU memory.

We will create 2 vertex buffers. The Staging buffer with CPU accessible memory to upload data from the vertex array to. We'll then use a buffer copy command to move the data from the staging buffer to the actual vertex buffer.

CPU             CPU                 GPU             GPU Register
Vertex Array -> Staging Buffer -> Vertex Buffer -> Shader

### Transfer queue
We don't need to create a new queue because the graphics queue family can transfer data.

<!-- TODO: I can try this -->
If you like a challenge, then you can still try to use a different queue family specifically for transfer operations. It will require you to make the following modifications to your program:
    - Modify `QueueFamilyIndices` and `findQueueFamilies` to explicitly look for a queue family with the `VK_QUEUE_TRANSFER` bit, but not the `VK_QUEUE_GRAPHICS_BIT`.
    - Modify `createLogicalDevice` to request a handle to the transfer queue
    - Create a second command pool for command buffers that are submitted on the transfer queue family
    - Change the `sharingMode` of resources to be `VK_SHARING_MODE_CONCURRENT` and specify both the graphics and transfer queue families
    - Submit any transfer commands like `vkCmdCopyBuffer` (which we'll be using in this chapter) to the transfer queue instead of the graphics queue

It's a bit of work, but it'll teach you a lot about how resources are shared between queue families.

### Abstracting buffer creation
To start with we need to update the BufferState constructor method to handle all buffer types and requirements.
Additionally, I need to abstract the memory 
Also, update the existing calls to use the new constructor.

### Using a staging buffer
We start by creating the staging buffer and populating it with the data. When creating the buffer we will use the `TRANSFER_SRC` Usage flag, and the `TRANSFER_DST` usage flag for the vertex buffer.
    - TRANSFER_SRC: Buffer can be used as a source in a memory transfer operation
    - TRANSFER_DST: Buffer can be used as a destination in a memory transfer operation

Now that the vertex buffer has a device_local memory type, we can't use memory map to move data.
To move the data from the staging to the vertex buffer, we need to use a command buffer. It's prefered to create a new command buffer because the imnplementation may be able to apply memroy allocation optimisations.

After making the new command buffer, then we need to begin the buffer and record the Copy command (`copy_buffer`) to move the data

Then we can submit the buffer and wait until it's done. We are not going to do anything else after this. In order to check when the command is done we can use a fence to schedule multiple transfers and wait for all of them.

Lastly, we should free the command buffer.

## Index Buffer
Objects tend to have repeating vertices which could lead to 50% more vertices than what we need. To fix this issue, we can use index buffers, which are basically list with pointers to the vertices we need to form the shape.

### Index Buffer Creation
We start by changing the vertices list to the unique vertices we will be using, and then creating an indices buffer that points to the location of the vertices we are going to use.

Then we will create an index buffer, using a staging buffer to transfer the indices to the GPU memory, 
and expose it to the renderer struct so that it can be used in the draw phase.

### Using an index buffer
During the drawing phase, we will have to bind the indes buffer to the cmd_buffer.
To do that use the `bind_index_buffer` with the `IndexBufferview` as the parameter which needs 3 things
    - the index buffer
    - offset
    - index_type: u16 or u32

Lastly, we need to tell the `cmd_buffer` to use the index we just binded. So we remove the `draw` call and in its place we add the `draw_indexed` that needs the following parameters
    - indices: a range of which indices to draw
    - base_vertex: the offset of the vertices buffer
    - instances: how many instances do we want to draw.

This will optimise the memory we use, especially when drawing large objects with thousands of vertices.

<!-- TODO: use a single buffer to store both data -->
Driver developer recommend to use a single buffer to store multiple types of data in a single buffer, like both the vertices data and the index data.